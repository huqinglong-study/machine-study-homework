'''
mean shift 聚类算法学习报告

一.基本思想和算法原理
计算某一样本点A向局部密度增加的方向移动，数据集密度的梯度方向就是密度增加最快的方向，计算
出该点下一步漂移的方向（A=M+A）。当该点不再移动时，与其周围点形成一个类簇，计算这个类簇
与历史类簇的距离，满足小于阈值D即合并为同一个类簇，不满足则自身形成一个类簇。直到所有的数
据点选取完毕。一般采用高斯核函数计算数据的核概率密度，其带宽决定了最终簇的个数。
算法的关键操作是通过感兴趣区域内的数据密度变化来计算中心点的漂移向量，从而移动中心点进行下
一次迭代，直到到达密度最大处（中心点不变）。从每个数据点出发都可以进行该操作，在这个过程，
统计出现在感兴趣区域内的数据的次数。该参数将在最后作为分类的依据。

二.算法步骤
1. 在未被标记的数据点中随机选择一个点作为起始中心点center；
2. 找出以center为中心半径为radius的区域中出现的所有数据点，认为这些点同属于一个聚类C。同时
    在该聚类中记录数据点出现的次数加1。
3. 以center为中心点，计算从center开始到集合M中每个元素的向量，将这些向量相加，得到向量shift。
4. center = center + shift。即center沿着shift的方向移动，移动距离是||shift||。
5. 重复步骤2、3、4，直到shift的很小（就是迭代到收敛），记住此时的center。注意，这个迭代过程
    中遇到的点都应该归类到簇C。
6. 如果收敛时当前簇C的center与其它已经存在的簇C2中心的距离小于阈值，那么把C2和C合并，数据
    点出现次数也对应合并。否则，把C作为新的聚类。
7. 重复1、2、3、4、5直到所有的点都被标记为已访问。
8. 分类：根据每个类，对每个点的访问频率，取访问频率最大的那个类，作为当前点集的所属类。

三.与KMean是算法比较
与K-Means算法不一样的是，Mean Shift算法可以自动决定类别的数目。
与K-Means算法一样的是，两者都用集合内数据点的均值进行中心点的移动。

四.优点
不用设置初始中心店，算法的结果比较稳定（因为每次漂移很小）
不用设置分类个数
可以处理任意形状的数据集

五.缺点
簇类结果取决于带宽的设置，带宽设置的太小，收敛结果慢，簇类个数多；带宽设置的太大，一些簇类
可能会丢失。
对于较大的特征空间，计算量会比较大

'''

