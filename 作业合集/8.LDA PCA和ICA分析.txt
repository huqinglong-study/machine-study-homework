线性判别分析LDA，主成分分析PCA，独立成分分析ICA 分析

一. LDA（潜在狄利克雷分布）
1.LDA的思想
      LDA是一种监督学习的降维技术，是一种处理文档的主题模型。LDA的思想可以用一句话概括，就是“投影后类内方差最小，类间方差最大”。
2.LDA的原理
      将带上标签的数据（点），通过投影的方法，投影到维度更低的空间中，使得投影后的点，会形成按类别区分，一簇一簇的情况，相同类别的点，将会在投影后的空间中更接近。
3.LDA的优点
      1）在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知            识。
      2）LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。
4.LDA的缺点
      1）LDA不适合对非高斯分布样本进行降维
　　2）LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。
　　3）LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。
　　4）LDA可能过度拟合数据。


二. PCA（主成分分析）
1. PCA的思想
      最重要的降维方法之一。主要工作是找出数据里最主要的方面，用数据里最主要的方面来代替原始数据。
2.PCA的原理
      将n维特征映射到k维上（k<n），这k维是全新的正交特征。
      这k维特征称为主元，是重新构造的k维特征，而不是简单地从n维特征中出去其余的n-k维特征
      选择这k维特征的依据是，将n维样本点转换为k维后，每一维的样本方差都很大。
3.PCA的优点
      1）仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　
　   2）各主成分之间正交，可消除原始数据成分间的相互影响的因素。
　   3）计算方法简单，主要运算是特征值分解，易于实现。
4.PCA的缺点
      1）主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。
      2）方差小的非主成分可能含有对样本差异的重要信息，因降维可能会对后续的数据处理有影响
5.PCA vs LDA
      相同点：1）两者均可以对数据进行降维。
　　　　      2）两者在降维时均使用了矩阵特征分解的思想。
　　　　      3）两者都假设数据符合高斯分布。

      不同点：1）LDA是有监督的降维方法，而PCA是无监督的降维方法
　　　　      2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。
　　　　      3）LDA除了可以用于降维，还可以用于分类。
　　　　      4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。

三.ICA（独立主成分分析）
1.ICA的思想
      ICA寻找的是最能使数据的相互独立的方向（维度），对比于PCA，PCA寻找的是正交的特征维度。换句话说：PCA是将一个混合的信号中的主要成分留下，而ICA是将一个混合信号中的所有信号拆开变回组合成该混合信号的独立信号。因为高斯分布的独立就等于不相关，所以当处理高斯分布的数据时，PCA就等于ICA。
      ICS是盲信号分析领域的一个强有力的方法，也是求非高斯分布数据隐含因子的方法

2.ICA的原理
      使用ICA的前提条件是，认为样本数据由独立非高斯分布的隐含因子产生，隐含因子个数等于特征数，要求的是隐含因子。
      而PCA认为特征是由K个正交的特征（也可以看作是隐含因子）生成的，我们要求的是数据在新特征上的投影。

      
